# ğŸ“º AnÃ¡lise de Kdramas: Um Pipeline de Dados End-to-End na Nuvem Azure

![Status do Projeto](https://img.shields.io/badge/status-concluÃ­do-brightgreen)
![LicenÃ§a](https://img.shields.io/badge/license-MIT-blue)

## ğŸ“– VisÃ£o Geral do Projeto

Este projeto demonstra a construÃ§Ã£o de um pipeline de dados completo, desde a ingestÃ£o de dados brutos de uma API pÃºblica atÃ© a criaÃ§Ã£o de um dashboard interativo. O objetivo foi transformar dados sobre dramas coreanos (Kdramas) da API do [The Movie Database (TMDB)](https://www.themoviedb.org/) em um conjunto de dados analÃ­tico, estruturado e pronto para BI, utilizando uma arquitetura **Data Lakehouse** moderna na nuvem Microsoft Azure.

O resultado final Ã© um dashboard interativo, construÃ­do com Streamlit e implantado na web, que permite a exploraÃ§Ã£o e anÃ¡lise das tendÃªncias e popularidade dos Kdramas lanÃ§ados nos Ãºltimos anos.

## ğŸ›ï¸ Arquitetura do Projeto

A soluÃ§Ã£o foi implementada seguindo a arquitetura MedalhÃ£o (Bronze, Silver, Gold), garantindo a qualidade, governanÃ§a e rastreabilidade dos dados em cada etapa do processo.

![Arquitetura do Projeto](https://raw.githubusercontent.com/nandodevs/kdrama_analytics_project/refs/heads/master/docs/imgs/arquitetura.png)


## ğŸ› ï¸ Tecnologias Utilizadas

* **Plataforma Cloud:** Microsoft Azure
* **Armazenamento de Dados:**
    * **Azure Data Lake Storage (ADLS) Gen2:** Para armazenar os dados nas camadas Bronze, Silver e Gold.
    * **Delta Lake:** Formato de tabela para garantir confiabilidade e performance no Data Lake.
    * **Azure SQL Database:** Atuando como Data Warehouse (camada de serviÃ§o) para o dashboard.
* **Processamento de Dados:**
    * **Azure Databricks:** Plataforma central para o desenvolvimento dos pipelines.
    * **Apache Spark (PySpark):** Motor de processamento distribuÃ­do para as transformaÃ§Ãµes de dados.
    * **Pandas:** Usado para prototipaÃ§Ã£o e manipulaÃ§Ã£o de dados local.
* **SeguranÃ§a:**
    * **Azure Key Vault:** Para gerenciamento seguro de segredos (chaves de API, senhas de banco de dados).
* **GovernanÃ§a:**
    * **Unity Catalog (Databricks):** Para gerenciar o acesso aos dados no Data Lake.
* **VisualizaÃ§Ã£o de Dados e AplicaÃ§Ã£o Web:**
    * **Streamlit:** Para a construÃ§Ã£o e deploy do dashboard interativo.
    * **Power BI:** Alternativa de ferramenta de BI para consumir os dados do SQL Server.
* **OrquestraÃ§Ã£o:**
    * **Databricks Workflows:** Orquestrador nativo para automatizar a execuÃ§Ã£o dos notebooks.
    * **Apache Airflow (com Docker):** Utilizado na fase de desenvolvimento local para orquestraÃ§Ã£o dos scripts Python.

## âœ¨ Funcionalidades

* **Pipeline ETL Completo:** ImplementaÃ§Ã£o de um pipeline de dados end-to-end, da extraÃ§Ã£o Ã  visualizaÃ§Ã£o.
* **Arquitetura MedalhÃ£o:** OrganizaÃ§Ã£o dos dados em camadas Bronze (brutos), Silver (limpos) e Gold (agregados), garantindo qualidade e governanÃ§a.
* **Data Lakehouse:** Uso do Delta Lake sobre o ADLS para combinar a flexibilidade de um Data Lake com a confiabilidade de um Data Warehouse.
* **Dashboard Interativo:** Uma aplicaÃ§Ã£o web construÃ­da com Streamlit que permite filtrar e analisar os dados de Kdramas por ano, gÃªnero, e popularidade.
* **Gerenciamento de Segredos:** ConfiguraÃ§Ã£o segura de credenciais utilizando Azure Key Vault e Databricks Secrets.
* **Deploy na Web:** ImplantaÃ§Ã£o da aplicaÃ§Ã£o Streamlit na nuvem (Render.com) usando Docker para um ambiente consistente e reproduzÃ­vel.

## ğŸ—‚ï¸ Estrutura do Projeto

```
kdrama_analytics_project/
â”œâ”€â”€ kdrama_dashboard/         # Projeto da aplicaÃ§Ã£o Streamlit
â”‚   â”œâ”€â”€ .streamlit/
â”‚   â”‚   â””â”€â”€ secrets.toml.example  # Exemplo do arquivo de segredos
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ dags/                     # (Opcional) DAGs do Airflow para desenvolvimento local
â”œâ”€â”€ notebooks/                # Notebooks do Databricks (Bronze, Silver, Gold)
â”œâ”€â”€ src/                      # (Opcional) Scripts Python originais para desenvolvimento local
â””â”€â”€ README.md
```

## ğŸš€ Como Executar o Dashboard (Localmente)

1.  **PrÃ©-requisitos:**
    * Python 3.9+
    * Conta no Azure com os recursos do projeto devidamente configurados (ADLS, SQL DB, Key Vault, Databricks).
    * Pipeline de dados no Databricks jÃ¡ executado para popular a camada Gold no SQL Server.
    * Microsoft ODBC Driver for SQL Server instalado na sua mÃ¡quina.

2.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/](https://github.com/)[seu-usuario]/[seu-repositorio].git
    cd [seu-repositorio]/kdrama_dashboard
    ```

3.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    # Windows
    venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```

4.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configure suas credenciais:**
    * Crie uma pasta `.streamlit` dentro de `kdrama_dashboard`.
    * Dentro dela, crie um arquivo `secrets.toml` com suas credenciais do Banco de Dados SQL do Azure. **Este arquivo nÃ£o deve ser enviado para o Git.**
    ```toml
    # .streamlit/secrets.toml
    [database]
    server = "seu_servidor_sql.database.windows.net"
    database = "seu_banco_de_dados"
    username = "seu_usuario"
    password = "sua_senha"
    driver = "ODBC Driver 18 for SQL Server"
    ```

6.  **Execute a aplicaÃ§Ã£o:**
    ```bash
    streamlit run app.py
    ```
    Seu navegador abrirÃ¡ automaticamente com o dashboard!

## ğŸ“ˆ Melhorias Futuras

* [ ] Agendar a execuÃ§Ã£o do pipeline no Azure com Databricks Workflows para atualizaÃ§Ã£o diÃ¡ria.
* [ ] Implementar testes de qualidade de dados com Great Expectations ou `dbt tests`.
* [ ] Adicionar mais visualizaÃ§Ãµes e anÃ¡lises ao dashboard.
* [ ] Criar um pipeline de CI/CD com GitHub Actions para automatizar o deploy do dashboard.

## âœï¸ Autor

* **[Seu Nome]**
* LinkedIn: `[Link para seu Linkedin]`
* GitHub: `[Link para seu GitHub]`

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.